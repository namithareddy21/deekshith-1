<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Real-Time Object Detection</title>

<style>
body {
    font-family: Arial, sans-serif;
    background: #f4f9fb;
    text-align: center;
}
h1 {
    margin: 20px;
}
button {
    padding: 12px 25px;
    border: none;
    background: #6ec7a1;
    color: white;
    font-size: 16px;
    border-radius: 20px;
    cursor: pointer;
    margin: 10px;
}
.container {
    display: flex;
    justify-content: center;
    gap: 40px;
    margin-top: 20px;
}
.box {
    background: white;
    padding: 15px;
    border-radius: 15px;
}
video, canvas {
    width: 320px;
    height: 240px;
    border-radius: 10px;
}
#info {
    margin-top: 30px;
    font-size: 18px;
}
</style>
</head>

<body>

<h1>REAL-TIME OBJECT DETECTION</h1>

<button onclick="startDetection()">Start Detection</button>
<button onclick="stopDetection()">Stop Detection</button>

<div class="container">
    <div class="box">
        <h3>Input (Live Camera)</h3>
        <video id="video" autoplay muted></video>
    </div>

    <div class="box">
        <h3>Output (Detection)</h3>
        <canvas id="canvas"></canvas>
    </div>
</div>

<div id="info">
    <p><b>Total Objects Detected:</b> <span id="count">0</span></p>
    <p id="desc">No objects detected</p>
</div>

<script>
let video = document.getElementById("video");
let canvas = document.getElementById("canvas");
let ctx = canvas.getContext("2d");
let rafId = null;
let isDetecting = false;

navigator.mediaDevices.getUserMedia({ video: true })
.then(stream => video.srcObject = stream);

// Resize canvas to match video on load
video.addEventListener('loadedmetadata', () => {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
});

function startDetection() {
    isDetecting = true;
    detectLoop();
}

function stopDetection() {
    isDetecting = false;
    if (rafId) {
        cancelAnimationFrame(rafId);
        rafId = null;
    }
}

async function detectLoop() {
    if (!isDetecting) return;
    
    // Set canvas size
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    
    // Clear and draw current frame
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(video, 0, 0);

    // Send frame for detection
    const blob = await new Promise(resolve => canvas.toBlob(resolve, "image/jpeg", 0.8));
    const formData = new FormData();
    formData.append("image", blob);

    try {
        const res = await fetch("/detect", {
            method: "POST",
            body: formData
        });
        const data = await res.json();

        // Update info
        document.getElementById("count").innerText = data.count || 0;
        document.getElementById("desc").innerText = 
            data.description?.length ? data.description.join(", ") : "No objects detected";

        // Draw bounding boxes (without redrawing video - it's already there)
        if (data.objects) {
            data.objects.forEach(obj => {
                const [x1, y1, x2, y2] = obj.box;
                ctx.strokeStyle = "lime";
                ctx.lineWidth = 3;
                ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);
                ctx.fillStyle = "lime";
                ctx.font = "bold 16px Arial";
                ctx.fillText(obj.label, x1, y1 - 5);
            });
        }
    } catch (error) {
        console.error("Detection error:", error);
    }

    // Continue loop smoothly
    rafId = requestAnimationFrame(detectLoop);
}
</script>

</body>
</html>
